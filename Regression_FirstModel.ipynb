{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmP7x85xcxkS"
   },
   "source": [
    "## About the Dataset\n",
    "We will be working on a data set that comes from the real estate industry in Boston (US). This database contains 14 attributes. The output variable refers to the median value of owner-occupied homes in 1000 USD's.\n",
    "\n",
    "* CRIM: per capita crime rate by town\n",
    "* ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS: proportion of non-retail business acres per town\n",
    "* CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* NOX: nitric oxides concentration (parts per 10 million)\n",
    "* RM: average number of rooms per dwelling\n",
    "* AGE: proportion of owner-occupied units built prior to 1940\n",
    "* DIS: weighted distances to five Boston employment centres\n",
    "* RAD: index of accessibility to radial highways\n",
    "* TAX: full-value property-tax rate per 10,000 USD\n",
    "* PTRATIO: pupil-teacher ratio by town\n",
    "* B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "* LSTAT: lower status of the population (%)\n",
    "* MEDV: Median value of owner-occupied homes in 1000 USD's (Output/Target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEWLuXd7BMrU"
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np # to perform calculations \n",
    "import pandas as pd # to read data\n",
    "import matplotlib.pyplot as plt # to visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fY_eewx0dhHt"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zlSaTd2W9rt"
   },
   "outputs": [],
   "source": [
    "# In read_csv() function, I have passed the location to where the file is located in a github page\n",
    "boston_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wze8jmpKtBG4"
   },
   "source": [
    "## View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Nwj5kkDjjQkx",
    "outputId": "0a69f714-5724-4ec9-856c-82f7e619b4a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS     NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n",
       "0  15.02340   0.0  18.10   0.0  0.6140  ...  666.0     20.2  349.48  24.91  12.0\n",
       "1   0.62739   0.0   8.14   0.0  0.5380  ...  307.0     21.0  395.62   8.47  19.9\n",
       "2   0.03466  35.0   6.06   0.0  0.4379  ...  304.0     16.9  362.25   7.83  19.4\n",
       "3   7.05042   0.0  18.10   0.0  0.6140  ...  666.0     20.2    2.52  23.29  13.4\n",
       "4   0.72580   0.0   8.14   0.0  0.5380  ...  307.0     21.0  390.95  11.28  18.2\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBv1fy29jAzm"
   },
   "source": [
    "### Separating Input Features and Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErMptop0jyng"
   },
   "outputs": [],
   "source": [
    "X = boston_data.drop('MEDV', axis = 1)    # Input Variables/features\n",
    "y = boston_data.MEDV      # output variables/features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgXPagiS3YKz"
   },
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1a1OFJmpUl2u"
   },
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Assign variables to capture train test split output\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train: independent/input feature data for training the model\n",
    "# y_train: dependent/output feature data for training the model\n",
    "# X_test: independent/input feature data for testing the model; will be used to predict the output values\n",
    "# y_test: original dependent/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n",
    " \n",
    "# test_size = 0.20: 20% of the data will go for test set and 70% of the data will go for train set\n",
    "# random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UfKNjpJqkPUf",
    "outputId": "560f2f83-590b-4d7b-fda7-96d0c3ad8224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# find the number of input features\n",
    "n_features = X.shape[1]\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwotIN0AU3Ci"
   },
   "source": [
    "# Training our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auQ5lPFrN7GN"
   },
   "source": [
    "### 1. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JY303RWVPzkD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential    # import Sequential from tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense  # import Dense from tensorflow.keras.layers\n",
    "from numpy.random import seed     # seed helps you to fix the randomness in the neural network.  \n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMDrQE9gQP6U"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D100gBMQSTn8"
   },
   "source": [
    "### 2. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "doYNy1jJQa7J"
   },
   "outputs": [],
   "source": [
    "# import RMSprop optimizer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(0.01)    # 0.01 is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNxnRf2uUqev"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQPPF22pVHMU"
   },
   "source": [
    "### 3. Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "WnG7pev1UxNs",
    "outputId": "291a66d5-71bb-49db-d7e3-a19b843977e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 840.9777\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 103.6628\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 179.7257\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 191.5660\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 140.9044\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 104.5120\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 116.0621\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 115.5886\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 107.1281\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 111.2766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f833662e160>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 42\n",
    "seed(seed_value)        # If you build the model with given parameters, set_random_seed will help you produce the same result on multiple execution\n",
    "\n",
    "\n",
    "# Recommended by Keras -------------------------------------------------------------------------------------\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "# Recommended by Keras -------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tensorflow.random.set_seed(seed_value) \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose = 1)    # fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_tKcVVzhJf8"
   },
   "source": [
    "### 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "qC63QoqchIa1",
    "outputId": "646c3c44-0773-4afd-84df-3dedc464bb9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833f82a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 64.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.87602233886719"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "li94FIlfnMBB"
   },
   "source": [
    "#### Hyperparameter Tunning\n",
    "The hyperparameters here in this notebook are:\n",
    "1. Learning Rate\n",
    "2. Epochs\n",
    "3. Batch Size\n",
    "\n",
    "We can try and change the values of these parameters and see the performance  of the model (evaluate the model) on X_test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XljOzViRoRbp"
   },
   "source": [
    "**Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "puhKnL9KKuZX",
    "outputId": "c3ecbeff-a8e1-4a57-d9f8-61750e124fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 35268.1797\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 559.4071\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.1511\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 139.3775\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 129.5609\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 122.8495\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 174.4107\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 142.8208\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 201.2038\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 223.9772\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833c0ed7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 122.8239\n",
      "The MSE value is:  122.82394409179688\n"
     ]
    }
   ],
   "source": [
    "####################### Complete example to check the performance of the model with different learning rates #######################################\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4BqC2Cfo159"
   },
   "outputs": [],
   "source": [
    "# Play with learning rate\n",
    "learning_rate = ?          # Replace ? with a floating-point number(decimal no.)\n",
    "epochs = 10\n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=30)       # Fit the model\n",
    "model.evaluate(X_test, y_test)                                  # Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mov9-uVwpmkd"
   },
   "source": [
    "**Epochs**\n",
    "\n",
    "A full training pass over the entire dataset such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zlZv50iKZPqo",
    "outputId": "36ef904c-7b07-4f63-954f-98b1a20b55f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9724.5732\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 582.0069\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 555.8216\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 521.9396\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 483.8689\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 444.7491\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 406.9054\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 371.2612\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 337.6587\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 306.2268\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 277.0800\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 250.4167\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 225.5309\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 202.9859\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 182.7787\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 164.8227\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 148.9729\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 135.4988\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.8988\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 114.1056\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 106.0993\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 100.3444\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 96.4450\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.5845\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 92.0008\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.3616\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0118\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.1522\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0371\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0573\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9193\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0018\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9787\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9684\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0983\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9732\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9472\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9128\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0360\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9132\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9193\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9364\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8977\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9577\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9994\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0100\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0025\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0074\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9457\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0306\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 91.1645\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9211\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9330\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8901\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 91.0190\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0044\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0272\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0088\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0335\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8989\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0687\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9590\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9457\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9054\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 91.0399\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9739\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9935\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9428\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9365\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9752\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9980\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0044\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0282\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0151\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9688\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9369\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0542\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9409\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.1157\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9322\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0418\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9078\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9901\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0322\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0187\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9214\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0568\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.8874\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9281\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0325\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9906\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0670\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8633\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9740\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0710\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9303\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9599\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9306\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0165\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.9525\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833f931ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 71.1146\n",
      "The MSE value is:  71.11458587646484\n"
     ]
    }
   ],
   "source": [
    "####################### Complete example to check the performance of the model with different epochs and learning rate = 0.01 #######################################\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train, y_train, epochs=100, batch_size=30, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUmO4ehKqC2_"
   },
   "outputs": [],
   "source": [
    "# Play with epochs\n",
    "learning_rate = 0.01         \n",
    "epochs = ?             # Replace ? with an integer\n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=30)       # Fit the model\n",
    "model.evaluate(X_test, y_test)                                  # Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8RUGIklqxKS"
   },
   "outputs": [],
   "source": [
    "# play with learning rate and epochs\n",
    "learning_rate = ?        # Replace ? with a floating-point number\n",
    "epochs = ?             # Replace ? with an integer\n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=30)       # Fit the model\n",
    "model.evaluate(X_test, y_test)                                  # Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcn3gB3Uq7u6"
   },
   "source": [
    "**Batch Size**\n",
    "\n",
    "The number of examples in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "DTSP63PTZ8hv",
    "outputId": "d0a90bd0-9e34-49e4-b351-fa035ae6df22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 27410.0840\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 211.4277\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 187.7308\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 157.6277\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 133.5317\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 206.0187\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 335.1154\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 166.5187\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 194.7234\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 181.1730\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833ec5cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 441.9634\n",
      "The MSE value is:  441.9634094238281\n"
     ]
    }
   ],
   "source": [
    "####################### Complete example to check the performance of the model with different batch size while keeping epochs as 30 and learning rate as 0.01 #######################################\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=40, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKik9O5grNa1"
   },
   "outputs": [],
   "source": [
    "# play with batch size\n",
    "learning_rate = 0.01        \n",
    "epochs = 150         \n",
    "batch = ?      # Replace ? with an integer    \n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch)     # fit the model\n",
    "model.evaluate(X_test, y_test)       # Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wYL0qp4fTv-"
   },
   "source": [
    "#### 5. Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-fWHtrMe8U_"
   },
   "outputs": [],
   "source": [
    "# Load new test data\n",
    "new_test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crRYu0YtiO5G"
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "model.predict(new_test_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DL_Day4: Linear_Regression with tf.keras - Beginners.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
